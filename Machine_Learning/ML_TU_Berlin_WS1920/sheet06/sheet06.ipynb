{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fisher Linear Discriminant\n",
    "\n",
    "In this exercise, you will apply Fisher Linear Discriminant as described in Chapter 3.8.2 of Duda et al. on the UCI Abalone dataset. A description of the dataset is given at the page https://archive.ics.uci.edu/ml/datasets/Abalone. The following two methods are provided for your convenience: \n",
    "\n",
    "\n",
    "* **`utils.Abalone.__init__(self)`** reads the Abalone data and instantiates three data matrices of size (1528, 7), (1307, 7), and (1342, 7) corresponding to the three classes in the dataset: *male (M)*, *female (F)*, and *infant (I)*.\n",
    "\n",
    "\n",
    "* **`utils.Abalone.plot(self,w)`** produces a histogram of the data when projected onto a vector `w`, and where each class is shown in a different color.\n",
    "\n",
    "\n",
    "Sample code that makes use of these two methods is given below. It loads the data, looks at the shape of instantiated matrices, and plots various projections of the data: (1) projection on the first dimension of the data, and (2) projection on a random direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import utils,numpy\n",
    "\n",
    "# Load the data\n",
    "abalone = utils.Abalone()\n",
    "\n",
    "# Print dataset size for each class\n",
    "print(abalone.M.shape,abalone.F.shape, abalone.I.shape)\n",
    "\n",
    "# Project data on the first dimension\n",
    "w1 = numpy.array([1,0,0,0,0,0,0])\n",
    "abalone.plot(w1,'projection on the first dimension')\n",
    "\n",
    "# Project data on a random direction\n",
    "w2 = numpy.random.normal(0,1,[7])\n",
    "w2 /= (w2**2).sum()**.5\n",
    "abalone.plot(w2,'projection on a random direction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation (10 + 5 + 5 = 20 P)\n",
    "\n",
    "* **Create a function `w = fisher(X1,X2)` that takes as input the data for two classes and returns the Fisher linear discriminant.**\n",
    "\n",
    "\n",
    "* **Create a function `objective(X1,X2,w)` that evaluates the objective defined in Equation 96 of Duda et al. for an arbitrary projection vector `w`.**\n",
    "\n",
    "\n",
    "* **Create a function `z = phi(X)` that returns a quadratic expansion for each data point `x` in the dataset. Such expansion consists of the vector `x` itself, to which we concatenate the vector of all pairwise products between elements of `x`.** In other words, letting $x = (x_1,\\dots,x_d)$ denote the $d$-dimensional data point, the quadratic expansion for this data point is a $d \\cdot (d+3)/2$ dimensional vector given by $\\phi(x) = (x_i)_{1 \\leq i \\leq d} \\cup (x_i x_j)_{1 \\leq i \\leq j \\leq d}$. For example, the quadratic expansion for $d=2$ is $(x_1,x_2,x_1^2,x_2^2,x_1 x_2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fisher(X1,X2):\n",
    "    ##### Replace by your code\n",
    "\n",
    "    # Calculate the mean vectors per class\n",
    "    X1_mean = np.array([numpy.mean(X1, axis=0)])\n",
    "    X2_mean = np.array([numpy.mean(X1, axis=0)])\n",
    "\n",
    "    # Calculate the scatter matrices for the SW (Scatter within) and sum the elements up\n",
    "    scatter_X1 = np.dot((X1 - X1_mean),(X1 - X1_mean).T)\n",
    "    scatter_X2 = np.dot((X2 - X2_mean),(X2 - X2_mean).T)\n",
    "\n",
    "    # Calculate the SW by adding the scatters within classes \n",
    "    SW = scatter_X1 +  scatter_X1\n",
    "    \n",
    "    W =  numpy.linalg.inv(SW).dot((X1_mean - X2_mean))\n",
    "    \n",
    "    return (w/numpy.linalg.norm(W))\n",
    "    \n",
    "    '''    \n",
    "    # Compute the Eigenvalues and Eigenvectors of SW^-1 SB\n",
    "    eigval, eigvec = np.linalg.eig(np.dot(np.linalg.inv(SW),SB))\n",
    "    '''\n",
    "    #####\n",
    "    \n",
    "def objective(X1,X2,w):\n",
    "    ##### Replace by your code\n",
    "    X1_mean = X1.mean(axis=0)  \n",
    "    X2_mean = X2.mean(axis=0) \n",
    "    data_mean = (X1_mean - X2_mean).reshape((X1.shape[1],1))\n",
    "    Sb = np.dot(data_mean.T, data_mean)\n",
    "    \n",
    "    X1_centered = X1 - u1\n",
    "    X2_centered = X2 - u2\n",
    "    scatter_X1 = np.dot(X1_centered.T, X1_centered)\n",
    "    scatter_X1 = np.dot(X2_centered.T, X2_centered)\n",
    "    SW = scatter_X1 + scatter_X2\n",
    "    \n",
    "    return w.dot(Sb.dot(w.T))/w.dot(Sw.dot(w.T))\n",
    "\n",
    "    #####\n",
    "    \n",
    "def expand(X):\n",
    "    ##### Replace by your code\n",
    "    d = X.shape[1]\n",
    "    size_after_expansion = d*(d+3)/2\n",
    "    result = numpy.zeros(int(size_after_expansion))\n",
    "    for x in X:\n",
    "        datapoint_exp = x\n",
    "        for i in range(0,x.size):\n",
    "            datapoint_exp = numpy.concatenate((datapoint_exp, x[i]*x[i:x.size]))\n",
    "        result = numpy.vstack((result, datapoint_exp))\n",
    "    return result[1:]\n",
    "    #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis (5 + 5 = 10 P)\n",
    "\n",
    "* **Print value of the objective function for each discriminated pair of classes (M/F, M/I, F/I), and for several values of `w`:**\n",
    "\n",
    "  * `w` is the difference between the mean vectors of the two classes.\n",
    "  * `w` is the Fisher linear discriminant.\n",
    "  * `w` is the Fisher linear discriminant (after quadratic expansion of the data).\n",
    "\n",
    "\n",
    "* **For the simple Fisher linear discriminant, plot a histogram of the projected data for each discriminated pair of classes using the function `utils.Abalone.plot()`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### REPLACE BY YOUR CODE\n",
    "%matplotlib inline\n",
    "M = abalone.M\n",
    "F = abalone.F\n",
    "I = abalone.I\n",
    "\n",
    "\n",
    "u_MF = M.mean(axis=0) - F.mean(axis=0)\n",
    "u_MI = M.mean(axis=0) - I.mean(axis=0)\n",
    "u_FI = F.mean(axis=0) - I.mean(axis=0)\n",
    "print(\"Means Linear {:.5f} {:.5f} {:.5f} \".format(objective(M,F,u_MF/numpy.linalg.norm(u_MF)  )\n",
    "                                            , objective(M,I,u_MI/numpy.linalg.norm(u_MI))\n",
    "                                            , objective(F,I,u_FI/numpy.linalg.norm(u_FI))))\n",
    "\n",
    "print(\"Fisher Linear {:.5f} {:.5f} {:.5f} \".format(objective(M,F,fisher(abalone.M,abalone.F) )\n",
    "                                            , objective(M,I,fisher(abalone.M,abalone.I))\n",
    "                                            , objective(F,I,fisher(abalone.F,abalone.I))))\n",
    "\n",
    "print(\"Fisher Quadratic Linear {:.5f} {:.5f} {:.5f} \".format(objective(expand(M),expand(F),fisher(expand(M),expand(F)) )\n",
    "                                            , objective(expand(M),expand(I),fisher(expand(M),expand(I)))\n",
    "                                            , objective(expand(F),expand(I),fisher(expand(F),expand(I)))))\n",
    "\n",
    "abalone.plot(fisher(abalone.M,abalone.F),\"Fisher Linear (Male/Female)\")\n",
    "abalone.plot(fisher(abalone.M,abalone.I),\"Fisher Linear (Male/Infant)\")\n",
    "abalone.plot(fisher(abalone.F,abalone.I),\"Fisher Linear (Female/Infant)\")\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
